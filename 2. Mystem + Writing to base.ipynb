{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import sqlite3\n",
    "from string import punctuation\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Как выглядит база данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpname = 'ALLPOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f'{corpname}.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS author\n",
    "(id INTEGER PRIMARY KEY AUTOINCREMENT, band text, genre text)\n",
    "\"\"\")\n",
    "# таблица автор: ключ, название группы, жанр\n",
    "# таблица песня: номер автора, название, год, альбом, текст, лемматизированный текст\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS song \n",
    "(id INTEGER PRIMARY KEY AUTOINCREMENT, author_id int, songname text, year int, album text, lyrics text, lemmatized_lyr text) \n",
    "    \"\"\")\n",
    "# таблика токен: номер песни, номер строки, токен(=слово как встретилось в lyrics с сохранением регистра), лемма, часть речи, разбор, позиция в предложении\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS token\n",
    "(id INTEGER PRIMARY KEY AUTOINCREMENT, song_id int, line int, token text, bast int, lem text, pos text, gram text, in_sent int) \n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Список необходимых паттернов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_br = re.compile('\\(.+\\)')\n",
    "pattern_encl = re.compile('(.+?)[\\?\\.\\;\\:\\!\\n]+ ?')\n",
    "pattern_text = re.compile('(.+) \\(.+\\)')\n",
    "pattern_date = re.compile('\\d{4}')\n",
    "stripadd = re.compile('.+\\]\\n')\n",
    "punct = punctuation + '...' + '``' + '\\'\\'' + '«' + '»' + '—' + ' '\n",
    "thrash = ['rmx', 'edit', 'раунд', 'round', 'cover', 'кавер', 'фристайл', 'freestyle', 'live', 'лайв', 'version', 'версия', 'mix', 'remix', 'микс', 'ремикс', 'скит', r'(Скит)','skit', 'демо', 'ark', 'список коллабораций']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разбор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Происходит в mystem консольно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forstem - папка, в которой находятся тексты, которые нужно разобрать + название текстового файла <br>\n",
    "mystem_path - расположение mystem.exe <br>\n",
    "output_filename - место, куда сохранится размеченный майстемом файл + назание файла (по умолчанию одинаковое и то, и то, различается форматом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeforstem(author_id, idx, song_id, sentences):\n",
    "    lines_to_parse = '\\n'.join([line for line in sentences])\n",
    "    forstem = os.path.join(r'\\Users\\mjo\\Documents\\GitHub\\RU-PopCultural-Corpus\\forstemming', f'{author_id}\\\\{author_id}_{idx}_{song_id}.txt')\n",
    "    with open(forstem, 'w+', encoding='utf-8') as f:\n",
    "        f.write(lines_to_parse)\n",
    "    mystem_path = os.path.join(r'\\Users\\mjo\\Desktop', 'mystem')\n",
    "    output_filename = os.path.join(r'\\Users\\mjo\\Documents\\GitHub\\RU-PopCultural-Corpus\\forstemming',  f'{author_id}\\\\{author_id}_{idx}_{song_id}.json')\n",
    "    os.system(f\"{mystem_path} {forstem} {output_filename} -n -i -d -s -c --eng-gr --format json\")\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_title(title):\n",
    "    check = 0\n",
    "    title_items = title.split(' ')\n",
    "    title_items = [item.strip(punctuation).lower() for item in title_items]\n",
    "    for item in title_items:\n",
    "        if item in thrash:\n",
    "            check = 1\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(rel_date, rel_ford):\n",
    "    if rel_date:\n",
    "        d_text = pattern_date.search(rel_date)\n",
    "        if d_text:\n",
    "            date = d_text.group(0)\n",
    "    elif rel_ford:\n",
    "        df_text = pattern_date.search(rel_ford)\n",
    "        if df_text:\n",
    "            date = df_text.group(0)\n",
    "        else:\n",
    "            date = '0'\n",
    "    else:\n",
    "        date = '0'\n",
    "    return int(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album(song):\n",
    "    try:\n",
    "        if song['album']['name']:\n",
    "            album = release_from_brakes('name', song['album'])\n",
    "            return album\n",
    "    except:\n",
    "        return 'undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_from_brakes(el, obj):\n",
    "    p_text = pattern_text.search(obj[el])\n",
    "    if p_text:\n",
    "        element = p_text.group(1)\n",
    "    else:\n",
    "        element = obj[el]\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(genius_raw):\n",
    "    if genius_raw:\n",
    "        without_unicode = genius_raw.replace('\\u2005', ' ').replace('\\xa0', ' ')  # заменяю не-классические табуляции на классические\n",
    "        without_comments = stripadd.sub('', without_unicode).replace('\\n\\n', '\\n').strip('\\n')  # удаляю текст из скобок [типа Припев 1] | такой текст будет записан в графу lyrics\n",
    "        lyric_lines = without_comments.splitlines()  #  делю текст на строки\n",
    "        extracted = find_additional(lyric_lines)  # ищу в строках все предложения\n",
    "        sentences = get_sentences(extracted)  # получаю список всех предложений текста\n",
    "        uniq_lists = only_uniqs(sentences)  # теперь в списке каждое предложение может встретиться только 1 раз, убраны любые повторения типа припевов\n",
    "        return without_comments, uniq_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_additional(lines):\n",
    "    extracted_lines = []\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            check_brake = pattern_br.search(line)\n",
    "            if check_brake:\n",
    "                additional_line = check_brake.group(0)\n",
    "                clean_original = line.replace(additional_line, '')\n",
    "                if clean_original:\n",
    "                    extracted_lines.append(clean_original)\n",
    "                extracted_lines.append(additional_line)\n",
    "            else:\n",
    "                extracted_lines.append(line)            \n",
    "    return extracted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(lines):\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        sent_list = pattern_encl.findall(line)\n",
    "        if sent_list:\n",
    "            for sent in sent_list:\n",
    "                sentences.append(sent.strip(punct))\n",
    "        else:\n",
    "            sentences.append(line.strip(punct))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(sentences):\n",
    "    word_list = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_words = [word.strip(punct) for word in word_tokenize(sentence) if word.strip(punct)]\n",
    "        separated = []\n",
    "        for i in range(len(cleaned_words)):\n",
    "            if len(cleaned_words[i].split('-'))>1:\n",
    "                cl_w = cleaned_words[i].split('-')\n",
    "                for cl in cl_w:\n",
    "                    separated.append(cl)\n",
    "            else:\n",
    "                separated.append(cleaned_words[i])\n",
    "        word_list.append(separated)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_uniqs(sent_wordlists):\n",
    "    uniq_list = []\n",
    "    uniq_lower = []\n",
    "    for sentence in sent_wordlists:\n",
    "        if sentence.lower().strip(' ') not in uniq_lower:\n",
    "            uniq_lower.append(sentence.lower().strip(' '))\n",
    "            uniq_list.append(sentence)\n",
    "    return uniq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_to_string(lemm_list):\n",
    "    lemmatized = []\n",
    "    for sent in lemm_list:\n",
    "        line_lyric = ' '.join([snt for snt in sent])\n",
    "        lemmatized.append(line_lyric)\n",
    "    lemma_lyrics = '\\n'.join([line for line in lemmatized])\n",
    "    return lemma_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пляски с mystem и перезаписями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyr_to_lem(token_id, filename, song_id):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    num_line = 0\n",
    "    num_insent = 0\n",
    "    listsfromsong = []\n",
    "    sentence_list = []\n",
    "    for it in text.splitlines():\n",
    "        line = json.loads(it)\n",
    "        if line.get('text', [])!=' ': \n",
    "            if line.get('text', []) =='\\r\\n':\n",
    "                num_insent = 0\n",
    "                if sentence_list:\n",
    "                    listsfromsong.append(sentence_list)\n",
    "                    num_line+=1\n",
    "                sentence_list = []\n",
    "            if line.get('analysis', []):\n",
    "                lemma = line.get('analysis', [])[0]['lex']\n",
    "                gr = line.get('analysis', [])[0]['gr'].replace('=', ',')\n",
    "                pos, _ = gr.split(',', 1)\n",
    "                token = line.get('text')\n",
    "                if line.get('analysis', [])[0].get('qual',[]):\n",
    "                    bastard = 1\n",
    "                else:\n",
    "                    bastard = 0\n",
    "                sentence_list.append(lemma) \n",
    "                cur.execute('INSERT INTO token VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "                            (token_id, song_id, num_line, token, bastard, lemma, pos, gr, num_insent ))\n",
    "                conn.commit()\n",
    "                num_insent +=1\n",
    "                token_id +=1\n",
    "    if sentence_list:\n",
    "        listsfromsong.append(sentence_list)\n",
    "    if listsfromsong:\n",
    "        lemmatized = lem_to_string(listsfromsong)\n",
    "        return token_id, lemmatized\n",
    "    else:\n",
    "        return token_id, listsfromsong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример записи корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = []\n",
    "token_id = 0\n",
    "song_ids = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f'{corpname}.db')\n",
    "cur = conn.cursor()\n",
    "for file in ffiles:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        artist_json = json.load(f)\n",
    "    checkfifty = 0  # проверка, что запишется не больше 50 песен на исполнителя; можно удалять, если ограничений нет\n",
    "    artist = release_from_brakes('name',artist_json).replace('\\xa0', ' ')   # может понадобиться заменить '\\u200b', если имя исполнителя с маленькой буквы('монеточка')\n",
    "    author_id = len(author_ids)\n",
    "    os.makedirs(str(author_id), exist_ok=True)  # папка для исполнителя\n",
    "    try:\n",
    "        shutil.move(str(author_id), r'forstemming')  # папка переносится в подпапку \"для разметки\"\n",
    "    except:\n",
    "        pass\n",
    "    titles = []\n",
    "    for idx, song in enumerate(artist_json['songs']):\n",
    "        if checkfifty<50:\n",
    "            date = extract_date(song['release_date'], song['release_date_for_display'])\n",
    "            if 2020>date>1989 or date==0:  # если есть какие-то условия по записи в определенные годы\n",
    "                title = release_from_brakes('title', song)\n",
    "                if title not in titles:\n",
    "                    check = check_title(title)\n",
    "                    if check == 0:\n",
    "                        song_id = song_ids\n",
    "                        album = get_album(song)\n",
    "                        try:\n",
    "                            lyrics, sentences = get_lyrics(song.get('lyrics', []))  # возвращает (1) очищенные строки с пунктуацией внутри (0_2) список предложений, который нужен дальше\n",
    "                            output_f = writeforstem(author_id, idx, song_id, sentences)\n",
    "                            token_id, lemmatized = lyr_to_lem(token_id, output_f, song_id)\n",
    "                            if lemmatized:  # если получилось сделать разметку, данные о песни записываются в базу\n",
    "                                cur.execute(  # пишу данные в базу текста\n",
    "                                    'INSERT INTO song VALUES (?, ?, ?, ?, ?, ?, ?)',\n",
    "                                    (song_id, author_id,\n",
    "                                     title, date, album,\n",
    "                                     lyrics, lemmatized))\n",
    "                                conn.commit()\n",
    "                                song_ids +=1\n",
    "                                checkfifty+=1\n",
    "                                titles.append(title)\n",
    "                        except:\n",
    "                            pass \n",
    "    author_ids.append(artist)\n",
    "    cur.execute('INSERT INTO author VALUES (?, ?, ?)', (author_id, artist, 'альтернатива'))  # здесь еще указывается жанр исполнителя\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сборка корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./corp/middlepop')  # папка, в которой находятся ваши файлы .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffiles =[os.path.join('./corp/middlepop/', f'{file}') for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда нужно ограничить количество песен по какому-то условию. Это можно сделать например вот так, сделав два цикла. <br>\n",
    "Например - 15 песен строго из до 2011 года. Остальные - самые популярные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f'{corpname}.db')\n",
    "cur = conn.cursor()\n",
    "for file in f2files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        artist_json = json.load(f)\n",
    "    checktwenty = 0  # проверка, что запишется не больше 20 песен на исполнителя\n",
    "    artist = release_from_brakes('name',artist_json).replace('\\xa0', ' ')  # может понадобиться заменить '\\u200b', если имя исполнителя с маленькой буквы('монеточка')\n",
    "    author_id = len(author_ids)\n",
    "    os.makedirs(str(author_id), exist_ok=True)\n",
    "    try:\n",
    "        shutil.move(str(author_id), r'forstemming')\n",
    "    except:\n",
    "        pass\n",
    "    titles = []\n",
    "    for idx, song in enumerate(artist_json['songs']):\n",
    "        if checktwenty<20:\n",
    "            date = extract_date(song['release_date'], song['release_date_for_display'])\n",
    "            if 2010>date>1989 or date==0:\n",
    "                title = release_from_brakes('title', song)\n",
    "                if title not in titles:\n",
    "                    check = check_title(title)\n",
    "                    if check == 0:\n",
    "                        song_id = song_ids\n",
    "                        album = get_album(song)\n",
    "                        try:\n",
    "                            lyrics, sentences = get_lyrics(song.get('lyrics', []))  # возвращает (1) очищенные строки с пунктуацией внутри (0_2) список предложений, который нужен дальше\n",
    "                            if detect(lyrics) == 'ru':\n",
    "                                output_f = writeforstem(author_id, idx, song_id, sentences)\n",
    "                                token_id, lemmatized = lyr_to_lem(token_id, output_f, song_id)\n",
    "                                if lemmatized:\n",
    "                                    song_ids +=1\n",
    "                                    cur.execute(  # пишу данные в базу текста\n",
    "                                        'INSERT INTO song VALUES (?, ?, ?, ?, ?, ?, ?)',\n",
    "                                        (song_id, author_id,\n",
    "                                         title, date, album,\n",
    "                                         lyrics, lemmatized))\n",
    "                                    conn.commit()\n",
    "                                    checktwenty+=1   \n",
    "                                    titles.append(title)\n",
    "                        except:\n",
    "                            pass \n",
    "    author_ids.append(artist)\n",
    "    cur.execute('INSERT INTO author VALUES (?, ?, ?)', (author_id, artist, 'поп'))\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вариант с листом excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'write2b.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songlist = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f'{corpname}.db')\n",
    "cur = conn.cursor()\n",
    "for song in llist:\n",
    "    artist = song[1]\n",
    "    author_id = song[0]\n",
    "    os.makedirs(str(author_id), exist_ok=True)\n",
    "    try:\n",
    "        shutil.move(str(author_id), r'forstemming')\n",
    "    except:\n",
    "        pass\n",
    "    date = song[4]\n",
    "    title = song[3]\n",
    "    song_id = song_ids\n",
    "    album = song[5]\n",
    "    lyrics, sentences = get_lyrics(song[6])  # возвращает (1) очищенные строки с пунктуацией внутри (0_2) список предложений, который нужен дальше\n",
    "    output_f = writeforstem(author_id, idx, song_id, sentences)\n",
    "    token_id, lemmatized = lyr_to_lem(token_id, output_f, song_id)\n",
    "    if lemmatized:\n",
    "        song_ids +=1\n",
    "        cur.execute(\n",
    "            'INSERT INTO song VALUES (?, ?, ?, ?, ?, ?, ?)',\n",
    "            (song_id, author_id,\n",
    "             title, date, album,\n",
    "             lyrics, lemmatized))\n",
    "        conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
